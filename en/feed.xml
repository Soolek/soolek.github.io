<?xml version="1.0" encoding="UTF-8"?> 
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CodeAndDrive.com</title>
    <description>Tomasz Sułkowski - Software developer, Drift racing driver</description>
    <link>http://www.CodeAndDrive.com/</link>
    <atom:link href="http://www.CodeAndDrive.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 10 Jun 2018 20:45:39 +0100</pubDate>
    <lastBuildDate>Sun, 10 Jun 2018 20:45:39 +0100</lastBuildDate>
    <generator>Jekyll v3.1.2</generator>
    
		
    
		
		  <item>
			<title>Autonomous driving using three simple vision algorithms</title>
			<description>&lt;p&gt;The purpose of this post is to familiarize the reader with three vision algorithms used for a simple autonomous driving algorithm.&lt;/p&gt;

&lt;p&gt;Autonomous driving is a very complicated subject. To make a car drive fully autonomously, big neural networks, machine learning and a lot of engineering needs to be applied. A very rudamentary autonomous driving algorithm can be created using three vision algorithms described in this post. The efficiency of this approach is very low, but it does not require any knowledge of artificial intelligence to be used.&lt;/p&gt;

&lt;p&gt;The goal of the algorithm is to drive along the road and control the speed accordingly to curves ahead. To see the algorithm in action an environment is going to be needed. Since testing in real world is expensive, complicated and probably illegal, a virtual environment is going to be used. There is a lot to choose from: &lt;a href=&quot;http://carla.org/&quot;&gt;Carla&lt;/a&gt;, &lt;a href=&quot;https://github.com/Microsoft/AirSim&quot;&gt;AirSim&lt;/a&gt;, or any other driving game that has basic programming support, like &lt;a href=&quot;https://www.rockstargames.com/V/&quot;&gt;GTAV&lt;/a&gt; with &lt;a href=&quot;http://www.dev-c.com/gtav/scripthookv/&quot;&gt;ScriptHook&lt;/a&gt; or &lt;a href=&quot;https://www.lfs.net/&quot;&gt;Live for speed&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Since the purpose of this blog entry is to focus on autonomous driving, obvious parts of the application are skipped (screen grabbing, simulation parameters reading and control override). You can look it up in the source here: &lt;a href=&quot;https://github.com/Soolek/AutoCruise/tree/master/AutoCruise&quot;&gt;AutoCruise&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The algorithm workflow uses three vision algorithms stacked on eachother: Perspective, Sobel and finally Sliding window.&lt;/p&gt;

&lt;h2 id=&quot;perspective&quot;&gt;Perspective&lt;/h2&gt;

&lt;p&gt;First algorithm used in the workflow is perspective transformation. It creates a birds-eye view from drivers point of view. The purpose of it is that it is far easier to find road edges and lanes as they will be parallel instead of converging to the vanishing point.&lt;/p&gt;

&lt;p&gt;The perspective transformation is a 3D transformation of the view pane, such that lower parts of the image will be put farther from observer point of view, while the upper parts will be closer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/autonomous_driving_using_three_simple_vision_algorithms/perspective.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Such transformation can be achieved by creating transformation matrix manually or use &lt;a href=&quot;https://docs.opencv.org/3.4.1/d9/dab/tutorial_homography.html&quot;&gt;FindHomography()&lt;/a&gt; function from opencv library. Using the second approach, the lower part of input image needs to be squeezed to counter the perspective projection of 3D world to 2D pane viewed from driver point of view:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/autonomous_driving_using_three_simple_vision_algorithms/perspective1.jpg&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/assets/images/posts/autonomous_driving_using_three_simple_vision_algorithms/perspective2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;With transformation matrix returned from FindHomography() new position of each pixel can be calculated from source image:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/autonomous_driving_using_three_simple_vision_algorithms/perspective_matrix1.jpg&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/assets/images/posts/autonomous_driving_using_three_simple_vision_algorithms/perspective_matrix2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;…or simply use opencv &lt;a href=&quot;https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html&quot;&gt;WarpPerspective()&lt;/a&gt; function, thus creating a perspective transformed image.&lt;/p&gt;

&lt;h2 id=&quot;sobel&quot;&gt;Sobel&lt;/h2&gt;

&lt;p&gt;The perspective transformed image is fed to next algorithm in workflow: an edge finding algorithm, Sobel. Its purpose is to highlight image edges that should be “interesting and meaningful” for driving algorithm. It will highlight image edges that distinguish themselves in x-axis in comparison to background noise.&lt;/p&gt;

&lt;p&gt;For learning purposes, the focus will be put on part of the image where a clear lane marking can be seen. Note that we are working on grey image, so each pixel is represented as 8-bit value with range from 0 to 255.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/autonomous_driving_using_three_simple_vision_algorithms/sobel1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It can be clearly seen that values go up from 119 to 149. Sobel algorithm transforms the image by comparing each pixels value to its right neighbor, therefor creating a difference map in form of an image which contains result of subtracting each pixels value to its right neighbor. Since the difference can be positive as well as negative, the result of subtraction is added to 128 (perfect grey color) so that the edge will be brighter if right neighbor pixel was brighter and darker edge in other case.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/autonomous_driving_using_three_simple_vision_algorithms/sobel2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To increase effectiveness of highlighting distinguished image edges a parameter called kernel has been introduced which compares a set of pixels to neighboring set of pixels in form of rectangle with side length of the kernel. This operation results in image that contains only edges that are highly distinguishable.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/autonomous_driving_using_three_simple_vision_algorithms/sobel3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;sliding-window-algorithm&quot;&gt;Sliding window algorithm&lt;/h2&gt;

&lt;p&gt;The last vision algorithm used in the workflow is Sliding window algorithm. Its purpose is to track image edges that are highly likely the road edges. This algorithm is quite resistant to image noise but not that accurate - just enough for purpose of a simple autonomous driving algorithm.&lt;/p&gt;

&lt;p&gt;Starting point of the Sliding window algorithm is placing a search window (of preconfigured size) in place where a lane should be present: the front end corner of the car. Next, the window is slidden upwards along the most distinguishable edge. Every time the window is moved upwards (by its height size) from its last position, a new horizontal position is calculated by weighted average on x-axis: the more pixels (with bigger values) are found on horizontal position inside the window, the more windows new position will be close to this position (in x-axis). Repeat this until the search window goes out of bounds of the image.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/autonomous_driving_using_three_simple_vision_algorithms/sliding_window.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After both left and right sliding windows have been moved to the upper boundaries of the input image, two paths have been created which should represent the road edges.&lt;/p&gt;

&lt;h2 id=&quot;driving-algorithm&quot;&gt;Driving algorithm&lt;/h2&gt;

&lt;p&gt;With the (probable) road edges found, a rudamentary driving algorithm is used: keep a steady 50kmh speed and slow down proportionally to lane curvature and steer to keep the car between the lanes. Driving precisely between the found lane edges needs to include steering parallelly to them. This needs a lot of experiments to dial steering right if done manually. To make most out of this approach, machine learning should be used with pre-recorded driving data. This way the algorithm should be able to clone the recorded driving style, but that is a topic for another blog entry.&lt;/p&gt;

&lt;p&gt;The final result looks like this:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://youtu.be/jKJhDTwFSVY?t=37&quot;&gt;&lt;img src=&quot;/assets/images/posts/autonomous_driving_using_three_simple_vision_algorithms/yt_link.jpg&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
			<pubDate>Fri, 01 Jun 2018 17:00:00 +0100</pubDate>
			<link>http://www.CodeAndDrive.com/en/posts/autonomous_driving_using_three_simple_vision_algorithms.en</link>
			<guid isPermaLink="true">http://www.CodeAndDrive.com/en/posts/autonomous_driving_using_three_simple_vision_algorithms.en</guid>
			
			
			<category>developer</category>
			
		  </item>
		
    
		
    
		
		  <item>
			<title>Positive side of being a developer</title>
			<description>&lt;p&gt;In the middle July 2016 - on Friday, when I was on my way to 3rd round of DriftOpen championship, I received a very strange call from work colleague:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Hi, …, our office is being closed now. Would you want to me to take something from your desk?”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I thought that’s a joke at first, so I had to check it with my other colleague. This info was so absurd that I just couldn’t believe it (there is a very long notice time in Poland). I witnessed one company going bankrupt but I surely didn’t expect this from a company that just opened a new big office in Poland. So I proceeded with packing everything for drift competition and finally took off for a trip from Gdansk to Koszalin.&lt;/p&gt;

&lt;p&gt;Unfortunately for me, the information about my current employer LowCostTravelGroup’s bankcrupcy has been proven (&lt;a href=&quot;http://www.gazetakrakowska.pl/strefa-biznesu/a/krakow-lowcosttravelgroup-zbankrutowal-ponad-200-osob-stracilo-prace,10411642/&quot;&gt;http://www.gazetakrakowska.pl/strefa-biznesu/a/krakow-lowcosttravelgroup-zbankrutowal-ponad-200-osob-stracilo-prace,10411642/&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&quot;at-first-there-was-doubt&quot;&gt;At first there was doubt&lt;/h2&gt;

&lt;p&gt;I was just about to make a U-turn and travel back since my budged was very tight for each competition. My entry fee was already paid. Same can be said about fuel, tires and hotel as well - so after some re-thinking I decided to continue my journey and work just on my ruined psyche until Monday on my trip back.&lt;/p&gt;

&lt;p&gt;Thankfully - I am a developer. Info about my employer going bankrupt spread very fast amongst headhunters and before I could even think what to do next, on Sunday (when I was still on track) my inbox looked like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/work_offers.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;…I was still shocked how so important things in life can change so fast.&lt;/p&gt;

&lt;p&gt;So, it is very good to be a developer in today’s times. I encourage everyone who still hasn’t decided what to do in life or thinks about changing his profession to become one. I could end up like famously quoted Twitter engineer:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The 37 minutes before I found a new job were the darkest moments of my life.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;not-as-bad-as-it-seems&quot;&gt;Not as bad as it seems…&lt;/h2&gt;

&lt;p&gt;With the amount of job offers growing exponentially I decided to give myself 3 weeks for finding an offer that would suit me best, and that was the best decision I have ever made. As it turned out, not only I was able to find an interesting job, but also one in which I will be able to make use of my car driving passion - &lt;a href=&quot;http://www.delphikrakow.pl&quot;&gt;Delphi Krakow&lt;/a&gt;, where I hope to work near autonomous cars.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=meTZKZp5QDY&quot;&gt;&lt;img src=&quot;/assets/images/youtube.png&quot; alt=&quot;&quot; class=&quot;yt-image-logo&quot; /&gt;&lt;img src=&quot;http://img.youtube.com/vi/meTZKZp5QDY/0.jpg&quot; alt=&quot;&quot; class=&quot;yt-image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I was employed mostly to get involved with .NET related projects, but quickly (about on my 3rd day) I was given a challenge: write a vision algorithm for marking road and cars in C++. Wow, that escalated quickly! I had to be extremely swift and learn quickly to come up with a viable solution, but this is what I always wanted to do - to get involved with autonomous cars.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/images/posts/AutoLineMarker_sreenshot.jpg&quot;&gt;&lt;img src=&quot;/assets/images/posts/AutoLineMarker_sreenshot_m.jpg&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks to both of my passions I went beyond any expectations and my program is currently commonly used in the company to aid in labelling details of the road.&lt;/p&gt;
</description>
			<pubDate>Wed, 01 Mar 2017 17:00:00 +0000</pubDate>
			<link>http://www.CodeAndDrive.com/en/posts/good_to_be_a_developer.en</link>
			<guid isPermaLink="true">http://www.CodeAndDrive.com/en/posts/good_to_be_a_developer.en</guid>
			
			
			<category>developer</category>
			
		  </item>
		
    
  </channel>
</rss>
